{"cells":[{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":330,"status":"ok","timestamp":1702407497508,"user":{"displayName":"Thomas Borges","userId":"17807100476140393050"},"user_tz":180},"id":"1obpAhnSaF-4"},"outputs":[],"source":["import pandas as pd\n","from collections import Counter\n","from nltk.corpus import stopwords\n","import string\n","import csv\n","import nltk\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":761,"status":"ok","timestamp":1702404719829,"user":{"displayName":"Thomas Borges","userId":"17807100476140393050"},"user_tz":180},"id":"QnNRpFkFlEOi","outputId":"4d27c50f-6300-4613-f68e-ae90b51e7eef"},"outputs":[],"source":["#run once\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{"id":"tu_09naOfvvG"},"source":["**Estatísticas descritivas dos datasets**\n","\n","Obrigatórias:\n","Word quantity\n","\n","Vou tentar:\n","Word frequency\n","Vocabulary size\n","Sentence length"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":283,"status":"ok","timestamp":1702408162349,"user":{"displayName":"Thomas Borges","userId":"17807100476140393050"},"user_tz":180},"id":"9nkzpbZZflQm"},"outputs":[],"source":["def print_stats(stats):\n","  for stat, value in stats.items():\n","    if stat == 'word_freq':\n","      continue\n","    else:\n","      print(f'{stat}: {value}')\n","\n","def clean_strings(strings):\n","  if isinstance(strings, list):\n","    cleaned_utterance = []\n","    for utterance in strings:\n","      utterance = utterance.replace(\"'s\", \"\")\n","      cleaned_utterance.append(utterance.translate(str.maketrans('', '', string.punctuation)))\n","    return cleaned_utterance\n","\n","  if isinstance(strings, str):\n","    return strings.translate(str.maketrans('', '', string.punctuation))\n","\n","def get_word_count(list_of_strings):\n","  punctuation = set(string.punctuation)\n","  word_stats = []\n","  for strings in list_of_strings:\n","    words = clean_strings(strings).split()\n","    words = [word for word in words if word.lower() not in punctuation]\n","    word_stats.append(len(words))\n","  return {\n","      'total_words': len(list_of_strings),\n","      'average_count': sum(word_stats)/len(word_stats),\n","      'max_count': max(word_stats),\n","      'min_count': min(word_stats)\n","  }\n","\n","def get_word_frequency(words, language):\n","  stop_words = set(stopwords.words(language))\n","  filtered_words = [word for word in words if word.lower() not in stop_words]\n","  word_frequency = Counter(filtered_words)\n","  return dict(sorted(word_frequency.items(), key=lambda item: item[1], reverse=True))\n","\n","def get_vocab_size(list_of_strings, words):\n","  total_vocab = len(set(words))\n","  word_stats = []\n","  for string in list_of_strings:\n","    words = ' '.join(clean_strings(string)).split()\n","    word_stats.append(len(set(words)))\n","  return {\n","      'total_vocab': total_vocab,\n","      'average_vocab': sum(word_stats)/len(word_stats),\n","      'max_vocab': max(word_stats),\n","      'min_vocab': min(word_stats)\n","  }\n","\n","def get_sent_len(list_of_strings):\n","  combined_text = ' '.join(list_of_strings)\n","  sentences = nltk.sent_tokenize(combined_text)\n","  sentence_lengths = []\n","  for sentence in sentences:\n","      words = nltk.word_tokenize(sentence)\n","      words = [word.lower() for word in words]\n","      sentence_lengths.append(len(words))\n","\n","  return{\n","      'avg_sentence_length' : sum(sentence_lengths) / len(sentence_lengths),\n","      'min_sentence_length' : min(sentence_lengths),\n","      'max_sentence_length' : max(sentence_lengths)\n","  }\n","\n","\n","def get_stats(list_of_strings, language):\n","  words_cleaned = ' '.join(clean_strings(list_of_strings)).split()\n","\n","  return {\n","      'word_freq' : get_word_frequency(words_cleaned, language),\n","      'word_count': get_word_count(list_of_strings),\n","      'sent_len': get_sent_len(list_of_strings),\n","      'vocab_size': get_vocab_size(list_of_strings, words_cleaned)\n","  }\n"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7449,"status":"ok","timestamp":1702408172949,"user":{"displayName":"Thomas Borges","userId":"17807100476140393050"},"user_tz":180},"id":"n6FpTIYaUPFr","outputId":"f56c6e09-c10b-4680-8cfd-3b643b569c05"},"outputs":[{"name":"stdout","output_type":"stream","text":["word_count: {'total_words': 3731, 'average_count': 21.3017957652104, 'max_count': 92, 'min_count': 2}\n","sent_len: {'avg_sentence_length': 22.99596875787352, 'min_sentence_length': 2, 'max_sentence_length': 63}\n","vocab_size: {'total_vocab': 12488, 'average_vocab': 24.042079871348164, 'max_vocab': 37, 'min_vocab': 9}\n","word_count: {'total_words': 372036, 'average_count': 20.474424518057393, 'max_count': 54, 'min_count': 1}\n","sent_len: {'avg_sentence_length': 20.50988070768046, 'min_sentence_length': 1, 'max_sentence_length': 143}\n","vocab_size: {'total_vocab': 144190, 'average_vocab': 22.27281768431012, 'max_vocab': 42, 'min_vocab': 2}\n"]}],"source":["rt = pd.read_json('./rotten/rottentomatoes.json')\n","\n","language = 'english'\n","consensus_stats = get_stats(rt._critic_consensus.tolist(), language)\n","print_stats(consensus_stats)\n","\n","critics_list = rt._critics.tolist()\n","all_critics = []\n","for critics in critics_list:\n","  for critic in critics.values():\n","    if critic == \".\": continue\n","    all_critics.append(critic)\n","\n","critics_stats = get_stats(all_critics, language)\n","print_stats(critics_stats)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["def save_json(file, data):\n","  with open(file, 'w') as f:\n","      json.dump(data, f)\n","\n","save_json('rotten/rotten_stats/input_stats.json', critics_stats)\n","save_json('rotten/rotten_stats/label_stats.json', consensus_stats)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21147,"status":"ok","timestamp":1702407528769,"user":{"displayName":"Thomas Borges","userId":"17807100476140393050"},"user_tz":180},"id":"Q1yKyWUnElyn","outputId":"f1dd0336-3989-4aac-f592-25f0f11c010e"},"outputs":[],"source":["# language = 'portuguese'\n","\n","# with open(\"./datasets/br_wac2wiki/output.csv\", \"r\", encoding='UTF-8') as f:\n","#     reader = csv.reader(f, delimiter=\"\\t\")\n","#     list_of_strings = [row[0] for row in reader]\n","#     wac_output = get_stats(list_of_strings, language)\n","#     print_stats(wac_output)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","from nltk.corpus import stopwords\n","import string\n","\n","# Download stopwords and punkt (run once)\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","# Sample list of strings\n","list_of_strings = [\n","    \"This is a sample sentence.\",\n","    \"Another sentence for demonstration purposes.\",\n","    \"A sample sentence similar to the first one.\"\n","]\n","\n","# Combine all strings into a single text\n","combined_text = ' '.join(list_of_strings)\n","\n","# Tokenize text into sentences\n","sentences = nltk.sent_tokenize(combined_text)\n","\n","# Get English stopwords and punctuation from NLTK\n","stop_words = set(stopwords.words('english'))\n","punctuation = set(string.punctuation)\n","\n","# Calculate sentence lengths\n","sentence_lengths = []\n","for sentence in sentences:\n","    # Tokenize sentence into words\n","    words = nltk.word_tokenize(sentence)\n","    \n","    # Remove stopwords and punctuation from words\n","    words = [word.lower() for word in words if word.lower() not in stop_words and word.lower() not in punctuation]\n","    \n","    # Append length of the remaining words (excluding stopwords and punctuation)\n","    sentence_lengths.append(len(words))\n","\n","# Calculate statistics\n","num_sentences = len(sentence_lengths)\n","if num_sentences > 0:\n","    avg_sentence_length = sum(sentence_lengths) / num_sentences\n","    min_sentence_length = min(sentence_lengths)\n","    max_sentence_length = max(sentence_lengths)\n","else:\n","    avg_sentence_length = 0\n","    min_sentence_length = 0\n","    max_sentence_length = 0\n","\n","# Display sentence length statistics\n","print(f\"Average Sentence Length: {avg_sentence_length:.2f}\")\n","print(f\"Minimum Sentence Length: {min_sentence_length}\")\n","print(f\"Maximum Sentence Length: {max_sentence_length}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOEluxW1PcqSVMtPf1+g4pc","mount_file_id":"1Kb5KUbfvzA4HhIsXh5kMLfWm3730u7bA","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
